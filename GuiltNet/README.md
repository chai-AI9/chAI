# 🕯 GuiltNet

> *“Man grows used to everything, the scoundrel!”*  
> — Dostoyevsky, *Crime and Punishment*

**GuiltNet** is an AI experiment that explores internal moral conflict through language. Inspired by Dostoyevsky’s deeply human characters, this project builds models that try to detect guilt, contradiction, and ethical tension in written dialogue.

Not sentiment analysis — but soul analysis.

---

## 💡 What It Does

- Extracts character dialogues from Dostoyevsky’s works (starting with *Crime and Punishment*)  
- Labels and classifies moral/emotional themes: guilt, justification, denial, confession  
- Trains models to detect **contradiction** and **emotional duality**

---

## 🔍 Techniques

- Sentence-level emotion annotation  
- Text classification with RoBERTa (or Longformer for longer passages)  
- Possibly combine with contradiction detection (e.g., NLI models)

---

## 📚 Possible Dataset Strategy

- Manual extraction from Dostoyevsky’s open-source texts (Project Gutenberg)  
- Labeling key quotes (e.g., Raskolnikov’s internal monologues, confessions)  
- Optional: crowdsource tagging for emotional tones

---

## 🌗 Goals

- Build a model that senses *moral dissonance* in literature  
- Inspire new ways to train AI on psychological and philosophical concepts  
- Spark conversation around emotional depth in NLP systems

---

## 💭 Future Ideas

- Compare characters across books (*Raskolnikov vs. Ivan Karamazov*)  
- Create a “confession classifier”  
- Use outputs to write new Dostoyevsky-style dialogues with tension-aware AI

---

## 🔎 Why It Matters

Most AI sees language in black-and-white.  
**GuiltNet** asks it to dwell in the gray — where real humanity lives.
